{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d76e80-e179-4016-8b56-a2b46fb59b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook was used to determine the application of one trained dataset onto another core\n",
    "# expression data was merged and cell annotations were included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963b78a2-252c-4b95-a7e8-3ab8bfb4b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires cell_annotation environment\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "import collections\n",
    "import scipy\n",
    "import sklearn\n",
    "from pySankey.sankey import sankey\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9488ed85-3f26-4de2-9a24-ad0c424c145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in util functions:\n",
    "# notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# project directory\n",
    "root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "os.chdir(root_dir)\n",
    "\n",
    "# for importing utils\n",
    "sys.path.append(os.path.join(root_dir, 'src', 'functions'))\n",
    "\n",
    "import annotation_utils\n",
    "import anno_class\n",
    "import core_class_test\n",
    "import classifier_class\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca78350b-fe32-4d2c-8237-86451aab2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in c7 as single core, will add n12 manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff128b4b-1a91-457d-aa27-694c1c82519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = pd.read_csv(os.path.join(root_dir, 'example_data', 'anal_cancer', 'raw', 'channelnames.txt'), header = None)[0]\n",
    "marker_info = {marker:[i, 0, 255] for i, marker in enumerate(markers)}\n",
    "\n",
    "# Set up as list if wanting to store more than one TMA core at a time\n",
    "summaries_dir = os.path.join(root_dir, 'example_data', 'anal_cancer', 'summaries')\n",
    "\n",
    "cores = collections.defaultdict()\n",
    "# set up in case more than one\n",
    "for core in ['C-7', 'N-12']:\n",
    "    core_coords = pd.read_csv(os.path.join(summaries_dir, f'{core}_coords.csv'))\n",
    "    core_coords.set_index('Object.ID', inplace = True)\n",
    "    \n",
    "    core_exprs = pd.read_csv(os.path.join(summaries_dir, f'{core}_expression.csv'))\n",
    "    core_exprs.set_index('Object.ID', inplace = True)\n",
    "    core_exprs.loc[core_coords.index,'X_coord'] = core_coords['Centroid.X.um']\n",
    "    core_exprs.loc[core_coords.index,'Y_coord'] = -1*core_coords['Centroid.Y.um'] # inverted y, for how images are displayed\n",
    "    core_image = annotation_utils.read_ome_tiff(os.path.join(root_dir, 'example_data', 'anal_cancer', 'processed', f'{core}.ome.tif'))\n",
    "\n",
    "    # first segmentation is bounding box of core, not needed - Qupath specific workflow\n",
    "    core_segments = annotation_utils.read_geom_json(os.path.join(root_dir, 'example_data', 'anal_cancer','segmentations', f'{core}.geojson'))[1:]\n",
    "    core_segs_restr = {}\n",
    "    \n",
    "    for feature in core_segments:\n",
    "        core_segs_restr.update(annotation_utils.transform_geometry(feature)) # converts geom_json object into dictionary of coordinates\n",
    "\n",
    "    cores[core] = core_class_test.core_data(expression_data = core_exprs, \n",
    "                                           image = core_image, # tif\n",
    "                                           segments = core_segs_restr, # restructured segmentations\n",
    "                                           core = core, # name\n",
    "                                           marker_info = marker_info) # marker channels / slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77071e-a10a-4593-973c-189c3a0c6528",
   "metadata": {},
   "source": [
    "Saving each as their own core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b929fafb-9ad7-45cf-8c2c-a7cddc3d285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = cores['C-7']\n",
    "annotations_dir = os.path.join(root_dir, 'example_data', 'anal_cancer', 'temp_annotations')\n",
    "\n",
    "result = pd.read_csv(os.path.join(annotations_dir, 'C7_annotations.csv'))\n",
    "result.columns = ['Object.ID', 'Annotation']\n",
    "result.value_counts('Annotation') # many more annotated than actually used in training\n",
    "\n",
    "result = result.set_index('Object.ID')['Annotation'].to_dict()\n",
    "c7.annotations = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6fe5bd-c1e6-49f5-89d8-1eec2c6c90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n12 = cores['N-12']\n",
    "annotations_dir = os.path.join(root_dir, 'example_data', 'anal_cancer', 'temp_annotations')\n",
    "\n",
    "result = pd.read_csv(os.path.join(annotations_dir, 'N12_annotations.csv'))\n",
    "result.columns = ['Object.ID', 'Annotation']\n",
    "result.value_counts('Annotation') # many more annotated than actually used in training\n",
    "\n",
    "result = result.set_index('Object.ID')['Annotation'].to_dict()\n",
    "n12.annotations = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e1353c-714e-4291-be7b-7b8863ec3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample from each to create smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fea3338-83c3-4443-a228-fbf064ac9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "merged = copy.deepcopy(c7) # using as example and will manually merge dataframes in each\n",
    "\n",
    "merged.expression_data = pd.concat([c7.expression_data, n12.expression_data], axis = 0)\n",
    "merged.plot_df = pd.concat([c7.plot_df, n12.plot_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9665b7f9-6a7d-4d5c-a312-99e8129da1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ subset to about 40 if each exists\n",
    "np.random.seed(5) # repdroduce sampling\n",
    "cells_per_class = 40\n",
    "\n",
    "# sampling used from each, independently\n",
    "\n",
    "core_dict = {'c7':[], 'n12':[]}\n",
    "# Group IDs by cell type\n",
    "for core in [c7, n12]:\n",
    "    new_dict = collections.defaultdict(list)\n",
    "    for ids, cell_type in core.annotations.items():\n",
    "        new_dict[cell_type].append(ids)  # Append IDs to the appropriate cell type list\n",
    "    \n",
    "    # Downsample to n IDs per cell type (or keep all if <n)\n",
    "    downsampled_ids = []\n",
    "    for cell_type, ids in new_dict.items():\n",
    "        sample_size = min(cells_per_class, len(ids))  # Use 40 or the total available if fewer than n\n",
    "        selected_ids = np.random.choice(ids, size = sample_size, replace = False)\n",
    "        downsampled_ids.extend(selected_ids.tolist())\n",
    "    \n",
    "    # Create final downsampled dictionary\n",
    "    downsampled_annotations = {ids: core.annotations[ids] for ids in downsampled_ids}\n",
    "    if core is c7:\n",
    "        core_dict['c7'] = downsampled_annotations\n",
    "    else:\n",
    "        core_dict['n12'] = downsampled_annotations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aac6594-3181-41cf-8497-f5e371601984",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_annotations = core_dict['c7'].copy()\n",
    "both_annotations.update(core_dict['n12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e006f6-028b-47b8-9c87-0ccd862dcf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\n"
     ]
    }
   ],
   "source": [
    "merged.annotations = both_annotations\n",
    "print(len(merged.annotations.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00696d85-56cb-42c5-93eb-4801503b56df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 89)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.expression_data.loc[both_annotations.keys(), :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bd0688-d74e-4847-85a3-08f91d4cf83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining features for random forest\n",
    "my_classifier = classifier_class.classify_cells(core_class = merged)\n",
    "\n",
    "rf_feats = merged.expression_data.columns[merged.expression_data.columns.str.contains('Cell_Mean')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c69beca-3ce4-4668-9c79-0b237dd26938",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = my_classifier.k_fold_cross_validation(use_params = rf_feats, \n",
    "                                           n_splits = 5, \n",
    "                                           random_state = 15, \n",
    "                                           use_imbalanced_rf = True, \n",
    "                                           use_smote = True, \n",
    "                                           n_trees = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749ff059-e69e-414e-8dd2-a535ccee0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_metrics(cv, metrics = ['recall', 'precision', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc018c89-2bd7-4962-a1b1-221881f420ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8809500409500408\n",
      "0.02961974407384372\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cv['accuracy']))\n",
    "print(np.std(cv['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7927768c-a23e-447b-be5e-1ea73350283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Class Counts:\n",
      "annotations\n",
      "Myeloid       80\n",
      "Stroma        80\n",
      "Epi           80\n",
      "Endothelia    80\n",
      "CD8_T         80\n",
      "CD4_T         70\n",
      "Treg          70\n",
      "Bcell         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts after filtering classes with < 2 samples:\n",
      "annotations\n",
      "Myeloid       80\n",
      "Stroma        80\n",
      "Epi           80\n",
      "Endothelia    80\n",
      "CD8_T         80\n",
      "CD4_T         70\n",
      "Treg          70\n",
      "Bcell         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_train after train_test_split:\n",
      "annotations\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "Myeloid       40\n",
      "Epi           40\n",
      "Stroma        40\n",
      "CD4_T         35\n",
      "Treg          35\n",
      "Bcell          7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_test after train_test_split:\n",
      "annotations\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "Myeloid       40\n",
      "Epi           40\n",
      "Stroma        40\n",
      "CD4_T         35\n",
      "Treg          35\n",
      "Bcell          7\n",
      "Name: count, dtype: int64\n",
      "min class count 7\n",
      "\n",
      "Applying SMOTE to the entire *training* set with k_neighbors=5\n",
      "\n",
      "SMOTE applied successfully to the entire *training* set.\n",
      "\n",
      "Class counts in y_train after SMOTE:\n",
      "annotations\n",
      "Bcell         40\n",
      "CD4_T         40\n",
      "CD8_T         40\n",
      "Endothelia    40\n",
      "Epi           40\n",
      "Myeloid       40\n",
      "Stroma        40\n",
      "Treg          40\n",
      "Name: count, dtype: int64\n",
      "Model Accuracy: 0.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bcell       0.75      0.43      0.55         7\n",
      "       CD4_T       0.87      0.77      0.82        35\n",
      "       CD8_T       0.95      0.93      0.94        40\n",
      "  Endothelia       0.80      0.90      0.85        40\n",
      "         Epi       0.90      0.88      0.89        40\n",
      "     Myeloid       0.74      0.80      0.77        40\n",
      "      Stroma       0.83      0.72      0.77        40\n",
      "        Treg       0.83      0.97      0.89        35\n",
      "\n",
      "    accuracy                           0.84       277\n",
      "   macro avg       0.83      0.80      0.81       277\n",
      "weighted avg       0.84      0.84      0.84       277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining features for random forest\n",
    "my_classifier = classifier_class.classify_cells(core_class = merged)\n",
    "merged.annotations = both_annotations\n",
    "\n",
    "my_classifier.train(split = 0.5,\n",
    "                    use_params = rf_feats, \n",
    "                    random_state = 15, \n",
    "                    use_imbalanced_rf = True, \n",
    "                    use_smote = True, \n",
    "                    n_trees = 200)\n",
    "my_classifier.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c8e863-fed3-4460-ba7b-238e98195ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = my_classifier.expression_data.loc[:,['annotations', 'predicted_annotation']]\n",
    "df = df.loc[df['annotations'] != '', :]\n",
    "df = df.loc[my_classifier.plot_data['used_in_training'] == False,:]\n",
    "\n",
    "plot_utils.contingency_plot(core = None, \n",
    "                            column1 = df['annotations'], \n",
    "                            column2 = df['predicted_annotation'], \n",
    "                            figsize = (3.5,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3daa6c6-95c5-4a43-a59f-c3bea136a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Class Counts:\n",
      "annotations\n",
      "Treg          40\n",
      "Myeloid       40\n",
      "Epi           40\n",
      "Stroma        40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "CD4_T         30\n",
      "Bcell         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts after filtering classes with < 2 samples:\n",
      "annotations\n",
      "Treg          40\n",
      "Myeloid       40\n",
      "Epi           40\n",
      "Stroma        40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "CD4_T         30\n",
      "Bcell         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_train after train_test_split:\n",
      "annotations\n",
      "Treg          40\n",
      "Myeloid       40\n",
      "Epi           40\n",
      "Stroma        40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "CD4_T         30\n",
      "Bcell         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_test after train_test_split:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# train one test other (trained on n12, predicted on c7)\n",
    "merged.annotations = core_dict['n12']\n",
    "\n",
    "my_classifier = classifier_class.classify_cells(core_class = merged)\n",
    "rf_feats = merged.expression_data.columns[merged.expression_data.columns.str.contains('Cell_Mean')]\n",
    "\n",
    "# full model for classification\n",
    "my_classifier.train(split = None, \n",
    "                    use_params = rf_feats, \n",
    "                    random_state = 19, \n",
    "                    use_imbalanced_rf = True, \n",
    "                    use_smote = False)\n",
    "\n",
    "my_classifier.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac908f0-2c17-40ba-8264-9f2f14bf10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_classifier.expression_data.loc[core_dict['c7'].keys(),'predicted_annotation'])\n",
    "df.loc[:,'annotations'] = list(core_dict['c7'].values())\n",
    "\n",
    "plot_utils.contingency_plot(core = None, \n",
    "                            column1 = df['annotations'], \n",
    "                            column2 = df['predicted_annotation'], \n",
    "                            figsize = (3.5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ddadd99-c893-4ed1-b58a-e9a8414a533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185185185185185\n"
     ]
    }
   ],
   "source": [
    "acc = np.sum(df.iloc[:,0] == df.iloc[:,1]) / df.shape[0]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d3789ad-75cd-4515-91c2-aae129b6e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Class Counts:\n",
      "annotations\n",
      "Myeloid       40\n",
      "Stroma        40\n",
      "Epi           40\n",
      "CD4_T         40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "Treg          30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts after filtering classes with < 2 samples:\n",
      "annotations\n",
      "Myeloid       40\n",
      "Stroma        40\n",
      "Epi           40\n",
      "CD4_T         40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "Treg          30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_train after train_test_split:\n",
      "annotations\n",
      "Myeloid       40\n",
      "Stroma        40\n",
      "Epi           40\n",
      "CD4_T         40\n",
      "Endothelia    40\n",
      "CD8_T         40\n",
      "Treg          30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class counts in y_test after train_test_split:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# train one test other (trained on c7, predicted on n12)\n",
    "merged.annotations = core_dict['c7']\n",
    "\n",
    "my_classifier = classifier_class.classify_cells(core_class = merged)\n",
    "rf_feats = merged.expression_data.columns[merged.expression_data.columns.str.contains('Cell_Mean')]\n",
    "\n",
    "# full model for classification\n",
    "my_classifier.train(split = None, \n",
    "                    use_params = rf_feats, \n",
    "                    random_state = 19, \n",
    "                    use_imbalanced_rf = True, \n",
    "                    use_smote = False)\n",
    "\n",
    "my_classifier.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "509a590b-edea-4b4d-826f-08b2456eb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_classifier.expression_data.loc[core_dict['n12'].keys(),'predicted_annotation'])\n",
    "df.loc[:,'annotations'] = list(core_dict['n12'].values())\n",
    "\n",
    "plot_utils.contingency_plot(core = None, \n",
    "                            column1 = df['annotations'], \n",
    "                            column2 = df['predicted_annotation'], \n",
    "                            figsize = (3.5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55d46d9e-b06e-4390-8749-9677170b244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676056338028169\n"
     ]
    }
   ],
   "source": [
    "acc = np.sum(df.iloc[:,0] == df.iloc[:,1]) / df.shape[0]\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
